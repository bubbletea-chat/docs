"""
Non-streaming Anthropic Claude Assistant Bot

This bot demonstrates how to use Anthropic's Claude models without streaming.
Claude excels at thoughtful, nuanced responses and complex reasoning.
"""

import os
from bubbletea_chat import chatbot, Text, Markdown, LLM


@chatbot(stream=False)
async def claude_assistant(prompt: str):
    """
    A thoughtful AI assistant powered by Claude 3 Opus
    
    This bot:
    - Uses Claude 3 Opus for highest quality responses
    - Returns complete, well-reasoned answers
    - Excellent for complex questions
    
    Make sure to set your Anthropic API key:
    export ANTHROPIC_API_KEY=your-api-key-here
    """
    # Initialize with Claude 3 Opus
    llm = LLM(model="claude-3-opus-20240229", temperature=0.7)
    
    # Get the complete response
    response = await llm.acomplete(prompt)
    
    return Text(response)


@chatbot(stream=False)
async def claude_sonnet_assistant(prompt: str):
    """
    A balanced assistant using Claude 3 Sonnet
    
    This bot:
    - Uses Claude 3 Sonnet for good balance of speed and quality
    - More cost-effective than Opus
    - Great for most use cases
    """
    llm = LLM(model="claude-3-sonnet-20240229", temperature=0.5)
    
    # Get the response
    response = await llm.acomplete(prompt)
    
    # Return formatted response
    return [
        Markdown(f"""
## Claude 3 Sonnet Response

{response}

---
*Model: Claude 3 Sonnet | Balanced performance*
        """)
    ]


@chatbot(stream=False)
async def claude_haiku_assistant(prompt: str):
    """
    A fast assistant using Claude 3 Haiku
    
    This bot:
    - Uses Claude 3 Haiku for rapid responses
    - Most cost-effective option
    - Great for simple queries
    """
    llm = LLM(model="claude-3-haiku-20240307", temperature=0.5)
    
    response = await llm.acomplete(prompt)
    
    return [
        Text(response),
        Text(""),
        Text("‚ö° Powered by Claude 3 Haiku - Fast and efficient!")
    ]


@chatbot(stream=False)
async def claude_researcher(prompt: str):
    """
    A research assistant that provides comprehensive analysis
    
    This bot:
    - Breaks down topics systematically
    - Provides multiple perspectives
    - Cites considerations and caveats
    """
    llm = LLM(
        model="claude-3-sonnet-20240229",
        temperature=0.3,  # Lower for research accuracy
        max_tokens=3000
    )
    
    # Research-oriented system prompt
    messages = [
        {
            "role": "system",
            "content": "You are a thorough research assistant. Analyze topics from multiple angles, consider various perspectives, identify key considerations, and provide balanced, well-researched responses. Use clear structure and cite important caveats."
        },
        {"role": "user", "content": prompt}
    ]
    
    # Get comprehensive analysis
    response = llm.with_messages(messages)
    
    return Markdown(f"""
## üîç Research Analysis

{response}

---
*Generated by Claude Research Assistant*
    """)


@chatbot(stream=False)
async def claude_writer(prompt: str):
    """
    A writing assistant for various content types
    
    This bot:
    - Helps with creative and professional writing
    - Adapts tone and style as needed
    - Provides polished content
    """
    llm = LLM(
        model="claude-3-sonnet-20240229",
        temperature=0.8,  # Higher for creative writing
        max_tokens=2000
    )
    
    # Analyze the type of writing needed
    analysis_prompt = f"What type of writing is this request asking for (e.g., creative, business, technical, academic)? Request: {prompt}"
    writing_type = await llm.acomplete(analysis_prompt)
    
    # Generate the content
    messages = [
        {
            "role": "system",
            "content": f"You are an expert writer specializing in {writing_type}. Create polished, engaging content that meets the user's needs."
        },
        {"role": "user", "content": prompt}
    ]
    
    content = llm.with_messages(messages)
    
    return [
        Markdown(f"## ‚úçÔ∏è Writing Type: {writing_type}"),
        Text(""),
        Markdown(content),
        Text(""),
        Markdown("---"),
        Text("Need revisions? Just ask!")
    ]


@chatbot(stream=False)
async def claude_tutor(prompt: str):
    """
    An educational tutor that adapts to learning needs
    
    This bot:
    - Explains concepts step-by-step
    - Provides examples and exercises
    - Checks understanding
    """
    llm = LLM(
        model="claude-3-sonnet-20240229",
        temperature=0.5,
        max_tokens=2500
    )
    
    # Educational system prompt
    messages = [
        {
            "role": "system",
            "content": "You are a patient, expert tutor. Break down concepts into digestible steps, provide clear examples, create simple exercises, and check for understanding. Use encouraging language and adapt to the student's level."
        },
        {"role": "user", "content": prompt}
    ]
    
    # Get educational content
    response = llm.with_messages(messages)
    
    # Add a practice question
    practice_prompt = f"Create a simple practice question related to: {prompt}"
    practice_question = await llm.acomplete(practice_prompt)
    
    return [
        Markdown("## üìñ Learning Session"),
        Markdown(response),
        Text(""),
        Markdown("### üéØ Practice Question"),
        Text(practice_question),
        Text(""),
        Text("üí° Take your time to think about it, then let me know your answer!")
    ]


@chatbot(stream=False)
async def claude_debate_bot(prompt: str):
    """
    A bot that presents multiple viewpoints on topics
    
    This bot:
    - Presents arguments from different perspectives
    - Maintains objectivity
    - Encourages critical thinking
    """
    llm = LLM(
        model="claude-3-sonnet-20240229",
        temperature=0.4,
        max_tokens=3000
    )
    
    # Generate multiple perspectives
    perspectives = []
    
    # Pro argument
    pro_msg = [
        {"role": "system", "content": "Present strong arguments in favor of the given topic."},
        {"role": "user", "content": prompt}
    ]
    pro_response = llm.with_messages(pro_msg)
    
    # Con argument
    con_msg = [
        {"role": "system", "content": "Present strong arguments against or questioning the given topic."},
        {"role": "user", "content": prompt}
    ]
    con_response = llm.with_messages(con_msg)
    
    # Balanced view
    balanced_msg = [
        {"role": "system", "content": "Provide a balanced, nuanced view considering multiple perspectives."},
        {"role": "user", "content": prompt}
    ]
    balanced_response = llm.with_messages(balanced_msg)
    
    return [
        Markdown(f"## ü§î Multiple Perspectives on: {prompt}"),
        Text(""),
        Markdown("### ‚úÖ Arguments For"),
        Markdown(pro_response),
        Text(""),
        Markdown("### ‚ùå Arguments Against"),
        Markdown(con_response),
        Text(""),
        Markdown("### ‚öñÔ∏è Balanced Perspective"),
        Markdown(balanced_response),
        Text(""),
        Markdown("---"),
        Text("Remember: Critical thinking means considering all sides!")
    ]


if __name__ == "__main__":
    # Run the Claude Sonnet assistant by default
    from bubbletea_chat import run_server
    run_server(claude_sonnet_assistant, port=8007)